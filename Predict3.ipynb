{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import datetime, date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from math import ceil\n",
    "\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
    "from keras.optimizers import RMSprop, Adam, SGD, Nadam\n",
    "from keras.layers.advanced_activations import *\n",
    "from keras.layers import Convolution1D, MaxPooling1D, AtrousConvolution1D\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras import regularizers\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('all/sales_train.csv')\n",
    "test = pd.read_csv('all/test.csv')\n",
    "submission = pd.read_csv('all/sample_submission.csv')\n",
    "items = pd.read_csv('all/items.csv')\n",
    "item_cats = pd.read_csv('all/item_categories.csv')\n",
    "shops = pd.read_csv('all/shops.csv')\n",
    "print(\"Ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_shops = test.shop_id.unique()\n",
    "train = train[train.shop_id.isin(test_shops)]\n",
    "test_items = test.item_id.unique()\n",
    "train = train[train.item_id.isin(test_items)]\n",
    "\n",
    "MAX_BLOCK_NUM = train.date_block_num.max()\n",
    "MAX_ITEM = len(test_items)\n",
    "MAX_CAT = len(item_cats)\n",
    "MAX_YEAR = 3\n",
    "MAX_MONTH = 4 # 7 8 9 10\n",
    "MAX_SHOP = len(test_shops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add categories\n",
    "train = train.set_index('item_id').join(items.set_index('item_id')).drop('item_name', axis=1).reset_index()\n",
    "\n",
    "\n",
    "train['month'] = train.date.apply(lambda x: datetime.strptime(x, '%d.%m.%Y').strftime('%m'))\n",
    "train['year'] = train.date.apply(lambda x: datetime.strptime(x, '%d.%m.%Y').strftime('%Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('date', axis=1)\n",
    "train = train.drop('item_category_id', axis=1)\n",
    "train = train.groupby(['shop_id', 'item_id', 'date_block_num', 'month', 'year']).sum()\n",
    "train = train.sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "cnt_scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(train.item_price.values.reshape(-1, 1))\n",
    "cnt_scaler.fit(train.item_cnt_day.values.reshape(-1, 1))\n",
    "\n",
    "train.item_price = scaler.transform(train.item_price.values.reshape(-1, 1))\n",
    "# train.item_cnt_day = cnt_scaler.transform(train.item_cnt_day.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = train.reset_index().set_index(['item_id', 'shop_id', 'date_block_num'])\n",
    "price = price.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "item_le = preprocessing.LabelEncoder()\n",
    "item_le.fit(test_items)\n",
    "item_dm = dict(zip(test_items, item_le.transform(test_items)))\n",
    "\n",
    "\n",
    "shop_le = preprocessing.LabelEncoder()\n",
    "shop_le.fit(test_shops)\n",
    "shop_dm = dict(zip(test_shops, shop_le.transform(test_shops)))\n",
    "\n",
    "\n",
    "month_le = preprocessing.LabelEncoder()\n",
    "month_le.fit(range(7,11))\n",
    "month_dm = dict(zip(range(7,11), month_le.transform(range(7,11))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepared\n"
     ]
    }
   ],
   "source": [
    "values = train.values.tolist()\n",
    "keys = train.index.values.tolist()\n",
    "table = []\n",
    "for i in range(len(item_dm)):\n",
    "    table.append([])\n",
    "    for j in range(len(shop_dm)):\n",
    "        table[i].append([])\n",
    "        for k in range(34):\n",
    "            table[i][j].append([0,10])\n",
    "print(\"prepared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = train.values.tolist()\n",
    "keys = train.index.values.tolist()\n",
    "for i in range(len(train.index)):\n",
    "    key = keys[i]\n",
    "    value = values[i]\n",
    "    table[item_dm[key[1]]][shop_dm[key[0]]][key[2]] = [value[0],value[1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(item_dm)):\n",
    "    table.append([])\n",
    "    for j in range(len(shop_dm)):\n",
    "        price = 0\n",
    "        count = 0\n",
    "        k = 0\n",
    "        while price==0 and k < 34:\n",
    "            if table[i][j][k][1]<9: \n",
    "                price = table[i][j][k][0]\n",
    "            k = k+1\n",
    "        k = 0\n",
    "        while k < 34:\n",
    "            if table[i][j][k][1]<9: \n",
    "                price = table[i][j][k][0]\n",
    "            else:\n",
    "                table[i][j][k][1] = 0\n",
    "                table[i][j][k][0] = price\n",
    "            k = k+1\n",
    "print(\"done\")\n",
    "# table[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "maxx = 0\n",
    "for i in range(len(item_dm)):\n",
    "    res.append([])\n",
    "    for j in range(len(shop_dm)):\n",
    "        res[i].append([])\n",
    "        summ = 0\n",
    "        for k in range(34):\n",
    "            summ = summ+table[i][j][k][1]\n",
    "        res[i][j] = summ\n",
    "        if summ>maxx:\n",
    "            maxx=summ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'plot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-a9798138f1b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'plot'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ITEM = len(test_items)\n",
    "MAX_MONTH = 32 \n",
    "MAX_SHOP = len(test_shops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# x_train = np.zeros((MAX_ITEM,MAX_SHOP*MAX_MONTH*2), dtype=np.float32)\n",
    "# for i, item in enumerate(table):\n",
    "#     for j, sales in enumerate(item):  \n",
    "#         for k in range(MAX_MONTH):\n",
    "#             x_train[i][j*MAX_MONTH*2+k*2] = table[i][j][k][0]\n",
    "#             x_train[i][j*MAX_MONTH*2+k*2+1] = table[i][j][k][1]\n",
    "            \n",
    "# y_train = np.zeros((MAX_ITEM,MAX_SHOP), dtype=np.float32)\n",
    "# for i, item in enumerate(table):\n",
    "#     for j, sales in enumerate(item):  \n",
    "#         y_train[i][j] = table[i][j][MAX_MONTH][1]\n",
    "\n",
    "x_train = np.zeros((MAX_ITEM, MAX_MONTH, MAX_SHOP*2), dtype=np.float32)\n",
    "for i, item in enumerate(table):\n",
    "    for j, sales in enumerate(item):  \n",
    "        for k in range(MAX_MONTH):\n",
    "            x_train[i][k][j*2] = table[i][j][k][0]\n",
    "            x_train[i][k][j*2+1] = table[i][j][k][1]\n",
    "            \n",
    "# y_train = np.zeros((MAX_ITEM,MAX_SHOP), dtype=np.float32)\n",
    "# for i, item in enumerate(table): \n",
    "#      for j, sales in enumerate(item):  \n",
    "#         y_train[i][j] = table[i][j][MAX_MONTH][1]\n",
    "y_train = np.zeros((MAX_ITEM,MAX_SHOP*5), dtype=np.float32)\n",
    "for i, item in enumerate(table): \n",
    "    for j, sales in enumerate(item):\n",
    "        val = table[i][j][MAX_MONTH][1]\n",
    "        if val>=5:\n",
    "            val = 4\n",
    "        y_train[i][int(j*5+val)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_val = np.zeros((MAX_ITEM,MAX_SHOP*MAX_MONTH*2), dtype=np.float32)\n",
    "# for i, item in enumerate(table):\n",
    "#     for j, sales in enumerate(item):  \n",
    "#         for k in range(MAX_MONTH):\n",
    "#             x_val[i][j*MAX_MONTH*2+k*2] = table[i][j][k+1][0]\n",
    "#             x_val[i][j*MAX_MONTH*2+k*2+1] = table[i][j][k+1][1]\n",
    "            \n",
    "\n",
    "\n",
    "# y_val = np.zeros((MAX_ITEM,MAX_SHOP), dtype=np.float32)\n",
    "# for i, item in enumerate(table):\n",
    "#     for j, sales in enumerate(item):  \n",
    "#         y_val[i][j] = table[i][j][MAX_MONTH+1][1]\n",
    "\n",
    "x_val = np.zeros((MAX_ITEM, MAX_MONTH, MAX_SHOP*2), dtype=np.float32)\n",
    "for i, item in enumerate(table):\n",
    "    for j, sales in enumerate(item):  \n",
    "        for k in range(MAX_MONTH):\n",
    "            x_val[i][k][j*2] = table[i][j][k+1][0]\n",
    "            x_val[i][k][j*2+1] = table[i][j][k+1][1]\n",
    "            \n",
    "y_val = np.zeros((MAX_ITEM,MAX_SHOP*5), dtype=np.float32)\n",
    "for i, item in enumerate(table): \n",
    "     for j, sales in enumerate(item):  \n",
    "        val = table[i][j][MAX_MONTH+1][1]\n",
    "        if val>=5:\n",
    "            val = 4\n",
    "        y_train[i][int(j*5+val)] = 1\n",
    "#         y_val[i][j] = table[i][j][MAX_MONTH+1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 84\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train[0]), len(x_train[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Train on 5100 samples, validate on 5100 samples\n",
      "Epoch 1/50\n",
      "5100/5100 [==============================] - 18s 4ms/step - loss: 0.2332 - val_loss: 2.3534e-05\n",
      "Epoch 2/50\n",
      "5100/5100 [==============================] - 1s 145us/step - loss: 0.2331 - val_loss: 2.4208e-05\n",
      "Epoch 3/50\n",
      "5100/5100 [==============================] - 1s 149us/step - loss: 0.2327 - val_loss: 2.6841e-05\n",
      "Epoch 4/50\n",
      "5100/5100 [==============================] - 1s 148us/step - loss: 0.2319 - val_loss: 3.9298e-05\n",
      "Epoch 5/50\n",
      "5100/5100 [==============================] - 1s 148us/step - loss: 0.2303 - val_loss: 7.4824e-05\n",
      "Epoch 6/50\n",
      "5100/5100 [==============================] - 1s 151us/step - loss: 0.2284 - val_loss: 1.1193e-04\n",
      "Epoch 7/50\n",
      "5100/5100 [==============================] - 1s 150us/step - loss: 0.2272 - val_loss: 1.3698e-04\n",
      "Epoch 8/50\n",
      "5100/5100 [==============================] - 1s 145us/step - loss: 0.2268 - val_loss: 1.4768e-04\n",
      "Epoch 9/50\n",
      "5100/5100 [==============================] - 1s 145us/step - loss: 0.2266 - val_loss: 1.5262e-04\n",
      "Epoch 10/50\n",
      "5100/5100 [==============================] - 1s 144us/step - loss: 0.2265 - val_loss: 1.5496e-04\n",
      "Epoch 11/50\n",
      "5100/5100 [==============================] - 1s 148us/step - loss: 0.2265 - val_loss: 1.5637e-04\n",
      "Epoch 12/50\n",
      "5100/5100 [==============================] - 1s 150us/step - loss: 0.2265 - val_loss: 1.5742e-04\n",
      "Epoch 13/50\n",
      "5100/5100 [==============================] - 1s 152us/step - loss: 0.2265 - val_loss: 1.5907e-04\n",
      "Epoch 14/50\n",
      "5100/5100 [==============================] - 1s 151us/step - loss: 0.2264 - val_loss: 1.6258e-04\n",
      "Epoch 15/50\n",
      "5100/5100 [==============================] - 1s 146us/step - loss: 0.2264 - val_loss: 1.6858e-04\n",
      "Epoch 16/50\n",
      "5100/5100 [==============================] - 1s 144us/step - loss: 0.2264 - val_loss: 1.7360e-04\n",
      "Epoch 17/50\n",
      "5100/5100 [==============================] - 1s 148us/step - loss: 0.2264 - val_loss: 1.7388e-04\n",
      "Epoch 18/50\n",
      "5100/5100 [==============================] - 1s 148us/step - loss: 0.2264 - val_loss: 1.7086e-04\n",
      "Epoch 19/50\n",
      "5100/5100 [==============================] - 1s 149us/step - loss: 0.2264 - val_loss: 1.6738e-04\n",
      "Epoch 20/50\n",
      "5100/5100 [==============================] - 1s 147us/step - loss: 0.2264 - val_loss: 1.6484e-04\n",
      "Epoch 21/50\n",
      "5100/5100 [==============================] - 1s 142us/step - loss: 0.2264 - val_loss: 1.6332e-04\n",
      "Epoch 22/50\n",
      "5100/5100 [==============================] - 1s 151us/step - loss: 0.2264 - val_loss: 1.6370e-04\n",
      "Epoch 23/50\n",
      "5100/5100 [==============================] - 1s 149us/step - loss: 0.2264 - val_loss: 1.6475e-04\n",
      "Epoch 24/50\n",
      "5100/5100 [==============================] - 1s 148us/step - loss: 0.2264 - val_loss: 1.6526e-04\n",
      "Epoch 25/50\n",
      "5100/5100 [==============================] - 1s 149us/step - loss: 0.2264 - val_loss: 1.6512e-04\n",
      "Epoch 26/50\n",
      "5100/5100 [==============================] - 1s 146us/step - loss: 0.2264 - val_loss: 1.6472e-04\n",
      "Epoch 27/50\n",
      "5100/5100 [==============================] - 1s 151us/step - loss: 0.2264 - val_loss: 1.6410e-04\n",
      "Epoch 28/50\n",
      "5100/5100 [==============================] - 1s 148us/step - loss: 0.2264 - val_loss: 1.6328e-04\n",
      "Epoch 29/50\n",
      "5100/5100 [==============================] - 1s 140us/step - loss: 0.2264 - val_loss: 1.6278e-04\n",
      "Epoch 30/50\n",
      "5100/5100 [==============================] - 1s 147us/step - loss: 0.2264 - val_loss: 1.6261e-04\n",
      "Epoch 31/50\n",
      "5100/5100 [==============================] - 1s 149us/step - loss: 0.2264 - val_loss: 1.6260e-04\n",
      "Epoch 32/50\n",
      "5100/5100 [==============================] - 1s 150us/step - loss: 0.2264 - val_loss: 1.6272e-04\n",
      "Epoch 33/50\n",
      "5100/5100 [==============================] - 1s 144us/step - loss: 0.2264 - val_loss: 1.6276e-04\n",
      "Epoch 34/50\n",
      "5100/5100 [==============================] - 1s 144us/step - loss: 0.2264 - val_loss: 1.6279e-04\n",
      "Epoch 35/50\n",
      "5100/5100 [==============================] - 1s 144us/step - loss: 0.2264 - val_loss: 1.6270e-04\n",
      "Epoch 36/50\n",
      "5100/5100 [==============================] - 1s 148us/step - loss: 0.2264 - val_loss: 1.6238e-04\n",
      "Epoch 37/50\n",
      "5100/5100 [==============================] - 1s 153us/step - loss: 0.2264 - val_loss: 1.6200e-04\n",
      "Epoch 38/50\n",
      "5100/5100 [==============================] - 1s 150us/step - loss: 0.2264 - val_loss: 1.6217e-04\n",
      "Epoch 39/50\n",
      "5100/5100 [==============================] - 1s 145us/step - loss: 0.2264 - val_loss: 1.6232e-04\n",
      "Epoch 40/50\n",
      "5100/5100 [==============================] - 1s 149us/step - loss: 0.2264 - val_loss: 1.6271e-04\n",
      "Epoch 41/50\n",
      "5100/5100 [==============================] - 1s 146us/step - loss: 0.2264 - val_loss: 1.6321e-04\n",
      "Epoch 42/50\n",
      "5100/5100 [==============================] - 1s 150us/step - loss: 0.2264 - val_loss: 1.6371e-04\n",
      "Epoch 43/50\n",
      "5100/5100 [==============================] - 1s 151us/step - loss: 0.2264 - val_loss: 1.6417e-04\n",
      "Epoch 44/50\n",
      "5100/5100 [==============================] - 1s 149us/step - loss: 0.2264 - val_loss: 1.6456e-04\n",
      "Epoch 45/50\n",
      "5100/5100 [==============================] - 1s 154us/step - loss: 0.2264 - val_loss: 1.6447e-04\n",
      "Epoch 46/50\n",
      "5100/5100 [==============================] - 1s 146us/step - loss: 0.2264 - val_loss: 1.6425e-04\n",
      "Epoch 47/50\n",
      "5100/5100 [==============================] - 1s 151us/step - loss: 0.2264 - val_loss: 1.6410e-04\n",
      "Epoch 48/50\n",
      "5100/5100 [==============================] - 1s 146us/step - loss: 0.2264 - val_loss: 1.6407e-04\n",
      "Epoch 49/50\n",
      "5100/5100 [==============================] - 1s 155us/step - loss: 0.2264 - val_loss: 1.6398e-04\n",
      "Epoch 50/50\n",
      "5100/5100 [==============================] - 1s 149us/step - loss: 0.2264 - val_loss: 1.6404e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1f31758f98>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "# model.add(LSTM(1, input_shape=(maxlen, length)))\n",
    "# model.add(Dense(1, activation='relu'))\n",
    "model.add(LSTM(32, return_sequences=True, input_shape=(32, 84),recurrent_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "model.add(LSTM(32, return_sequences=True, input_shape=(32, 84),recurrent_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(LSTM(32, return_sequences=True, input_shape=(32, 84)))\n",
    "model.add(LSTM(32, return_sequences=False, input_shape=(32, 84),recurrent_initializer='he_uniform'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(LeakyReLU())\n",
    "# model.add(Dense(1, activation='relu'))\n",
    "\n",
    "# model.add(Dense(64, input_dim=(2688), kernel_initializer='he_uniform'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(LeakyReLU())\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(32))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(LeakyReLU())\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(64))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(LeakyReLU())\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "# model.add(Dense(128, input_dim=(2688)))\n",
    "# model.add(Dense(64))\n",
    "# model.add(Dense(64))\n",
    "\n",
    "# model.add(Dense(256))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(LeakyReLU())\n",
    "# model.add(Dropout(0.3))\n",
    "\n",
    "# model.add(Dense(16))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(LeakyReLU())\n",
    "model.add(Dense(MAX_SHOP*5, activation='softmax'))\n",
    "# model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "# from keras.optimizers import RMSprop, Adam, SGD, Nadam\n",
    "# optimizer = RMSprop(lr=0.005)\n",
    "# optimizer = SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
    "# optimizer = Nadam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "optimizer = Adam(lr=0.005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "\n",
    "# model.fit(x_train, y_train, batch_size=2048, epochs=50, validation_data=(x_val, y_val))\n",
    "model.fit(x_train, y_train, batch_size=2048, epochs=50, validation_data=(x_val, y_val))\n",
    "# model.fit(x_train, y_train, batch_size=2048, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_52 (LSTM)               (None, 32, 32)            14976     \n",
      "_________________________________________________________________\n",
      "batch_normalization_111 (Bat (None, 32, 32)            128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_110 (LeakyReLU)  (None, 32, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm_53 (LSTM)               (None, 32, 32)            8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_112 (Bat (None, 32, 32)            128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_111 (LeakyReLU)  (None, 32, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm_54 (LSTM)               (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_136 (Dense)            (None, 210)               6930      \n",
      "=================================================================\n",
      "Total params: 38,802\n",
      "Trainable params: 38,674\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAX_ITEM = len(test_items)\n",
    "# MAX_MONTH = 32 \n",
    "# MAX_SHOP = len(test_shops)\n",
    "\n",
    "# month_count = 32\n",
    "# x_test = np.zeros((MAX_ITEM,MAX_SHOP*MAX_MONTH*2), dtype=np.float32)\n",
    "# for i, item in enumerate(table):\n",
    "#     for j, sales in enumerate(item):  \n",
    "#         for k in range(MAX_MONTH):\n",
    "#             x_test[i][j*MAX_MONTH*2+k*2] = table[i][j][k+2][0]\n",
    "#             x_test[i][j*MAX_MONTH*2+k*2+1] = table[i][j][k+2][1]\n",
    "            \n",
    "            \n",
    "x_test = np.zeros((MAX_ITEM, MAX_MONTH, MAX_SHOP*2), dtype=np.float32)\n",
    "for i, item in enumerate(table):\n",
    "    for j, sales in enumerate(item):  \n",
    "        for k in range(MAX_MONTH):\n",
    "            x_test[i][k][j*2] = table[i][j][k+2][0]\n",
    "            x_test[i][k][j*2+1] = table[i][j][k+2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        , -0.15018865,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        , -0.15018865,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.40062827e-02, 1.79483891e-06, 1.32155208e-06, 2.44939429e-06,\n",
       "       2.20105699e-06, 4.23374288e-02, 1.83745851e-06, 1.08320864e-06,\n",
       "       1.72728187e-06, 1.84071371e-06, 3.61154303e-02, 3.79306675e-06,\n",
       "       2.01508033e-06, 1.98901853e-06, 1.76862602e-06, 2.47798003e-02,\n",
       "       2.36423989e-06, 2.27325768e-06, 2.30488490e-06, 2.06634149e-06,\n",
       "       7.56919151e-03, 5.65094115e-06, 1.86198167e-06, 1.19420065e-06,\n",
       "       2.41746898e-06, 1.39330439e-02, 2.53451503e-06, 2.13967837e-06,\n",
       "       1.65792335e-06, 1.03226910e-06, 5.16091585e-02, 3.67291796e-06,\n",
       "       2.16585227e-06, 1.95733219e-06, 1.60680406e-06, 2.84844898e-02,\n",
       "       1.57260604e-06, 1.40646011e-06, 2.07964854e-06, 2.26017505e-06,\n",
       "       3.56795639e-02, 2.47934258e-06, 1.46514378e-06, 1.15042576e-06,\n",
       "       2.03657510e-06, 1.65591370e-02, 1.82980614e-06, 1.63527955e-06,\n",
       "       1.13816100e-06, 2.50957805e-06, 2.48355865e-02, 1.82418182e-06,\n",
       "       1.52385871e-06, 2.27727855e-06, 1.60379420e-06, 1.91739853e-02,\n",
       "       1.94204995e-06, 1.84585019e-06, 2.32714638e-06, 1.42593126e-06,\n",
       "       1.45578915e-02, 2.13206840e-06, 1.50201447e-06, 1.42300655e-06,\n",
       "       1.22618201e-06, 1.55219389e-03, 2.20124184e-06, 1.68506972e-06,\n",
       "       2.05987817e-06, 2.40664599e-06, 3.18988636e-02, 2.97906672e-06,\n",
       "       2.07493144e-06, 2.57004194e-06, 1.37976861e-06, 1.83803346e-02,\n",
       "       2.49073014e-06, 1.22046765e-06, 2.32747061e-06, 1.18834987e-06,\n",
       "       1.53437592e-04, 6.47375919e-06, 1.74689933e-06, 2.21149344e-06,\n",
       "       1.57701402e-06, 2.67607048e-02, 3.11840790e-06, 2.02622414e-06,\n",
       "       1.30889123e-06, 1.71503848e-06, 4.95163084e-04, 2.56715362e-06,\n",
       "       1.82758424e-06, 1.77781703e-06, 2.04783237e-06, 6.66982523e-05,\n",
       "       5.02289367e-06, 1.97258396e-06, 2.00480213e-06, 1.46671380e-06,\n",
       "       4.82950769e-02, 2.45049705e-06, 1.49421510e-06, 1.51534448e-06,\n",
       "       1.63770653e-06, 6.12392183e-03, 1.86887348e-06, 1.65016547e-06,\n",
       "       2.37561972e-06, 1.64193682e-06, 6.32306635e-02, 1.66879897e-06,\n",
       "       2.79066421e-06, 1.52183702e-06, 2.33395190e-06, 3.43225524e-02,\n",
       "       2.97275210e-06, 2.57977081e-06, 1.64629239e-06, 1.26181931e-06,\n",
       "       1.44398427e-02, 3.45231592e-06, 2.25208714e-06, 7.71778389e-07,\n",
       "       3.15035595e-06, 3.82643826e-02, 1.75924436e-06, 2.30004753e-06,\n",
       "       1.48217271e-06, 1.55003477e-06, 3.67633849e-02, 1.71398710e-06,\n",
       "       2.14932561e-06, 2.60368188e-06, 2.78527455e-06, 2.88954558e-04,\n",
       "       3.46054026e-06, 1.61859884e-06, 2.81232633e-06, 1.15587386e-06,\n",
       "       3.84847894e-02, 2.25707754e-06, 1.09125472e-06, 1.76943070e-06,\n",
       "       1.51870108e-06, 4.41843569e-02, 3.84194891e-06, 1.95157077e-06,\n",
       "       1.31356046e-06, 1.25616293e-06, 1.47268828e-02, 2.72296529e-06,\n",
       "       1.76588719e-06, 1.11553402e-06, 3.49396691e-06, 2.36554421e-03,\n",
       "       1.78186360e-06, 2.22933795e-06, 2.18715036e-06, 3.23956488e-06,\n",
       "       1.93435624e-02, 2.34864387e-06, 1.59369938e-06, 2.61662308e-06,\n",
       "       2.37315612e-06, 3.88859659e-02, 2.92685922e-06, 1.19957906e-06,\n",
       "       1.30933324e-06, 1.81750158e-06, 2.79724970e-02, 2.12340206e-06,\n",
       "       1.73738090e-06, 1.39981762e-06, 1.92334551e-06, 2.71277037e-02,\n",
       "       2.34236290e-06, 1.31663830e-06, 1.76951517e-06, 2.01715852e-06,\n",
       "       1.95608772e-02, 2.00400314e-06, 1.54322470e-06, 1.69690964e-06,\n",
       "       1.04368348e-06, 3.66783068e-02, 1.97046302e-06, 1.62766196e-06,\n",
       "       1.31484023e-06, 1.75992557e-06, 2.03976519e-02, 2.14522993e-06,\n",
       "       1.99002784e-06, 1.75738126e-06, 1.34024515e-06, 4.36071656e-04,\n",
       "       3.20434901e-06, 1.83558780e-06, 1.86752834e-06, 3.05022536e-06,\n",
       "       3.42899328e-03, 2.77732011e-06, 1.21198661e-06, 1.43037278e-06,\n",
       "       1.34097002e-06, 3.53868976e-02, 2.83800546e-06, 1.85058104e-06,\n",
       "       2.11234783e-06, 1.46083948e-06], dtype=float32)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test = cnt_scaler.inverse_transform(predict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6955707"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_test[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.6955707, 2.6955707, 2.6955707, 2.6955707, 2.6955707, 2.6955707,\n",
       "       2.6955707, 2.6955707, 2.6955707, 2.6955707, 2.6955707, 2.6955707,\n",
       "       2.6955707, 2.6955707, 2.6955707, 2.6955707, 2.6955707, 2.6955707,\n",
       "       2.6955707, 2.6955707, 2.6955707, 2.6955707, 2.6955707, 2.6955707,\n",
       "       2.6955707, 2.6955707, 2.6955707, 2.6955707, 2.6955707, 2.6955707,\n",
       "       2.6955707, 2.6955707, 2.6955707, 2.6955707, 2.6955707, 2.6955707,\n",
       "       2.6955707, 2.6955707, 2.6955707, 2.6955707, 2.6955707, 2.6955707],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252950.0\n",
      "38947.0\n"
     ]
    }
   ],
   "source": [
    "summ = 0 \n",
    "\n",
    "# for i in range(len(item_dm)):\n",
    "# #     res.append([])\n",
    "#     for j in range(len(shop_dm)):\n",
    "# #         res[i].append([])\n",
    "# #         summ = 0\n",
    "# #         for k in range(34):\n",
    "# #             summ = summ+table[i][j][k][1]\n",
    "#         summ = table[i][j][33][1] + summ\n",
    "# #         if summ>maxx:\n",
    "# #             maxx=summ\n",
    "\n",
    "# print(summ)\n",
    "# summ = 0\n",
    "for k in range(6):\n",
    "    for sentence in test2.index.values.tolist():\n",
    "        (shop_id, item_id) = (sentence[0], sentence[1])\n",
    "        iid = item_dm[item_id]\n",
    "        sid = shop_dm[shop_id]\n",
    "        summ = summ + table[iid][sid][28+k][1]\n",
    "        \n",
    "print(summ)\n",
    "\n",
    "summ = 0\n",
    "for sentence in test2.index.values.tolist():\n",
    "        (shop_id, item_id) = (sentence[0], sentence[1])\n",
    "        iid = item_dm[item_id]\n",
    "        sid = shop_dm[shop_id]\n",
    "        summ = summ + table[iid][sid][34-12][1]\n",
    "print(summ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28072\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('all/test.csv')\n",
    "test = test.set_index(['shop_id', 'item_id'])\n",
    "test['item_cnt_month'] = 0\n",
    "\n",
    "test2 = test\n",
    "test2\n",
    "summ = 0\n",
    "for index, sentence in enumerate(test2.index.values.tolist()):\n",
    "#     print(index, sentence)\n",
    "    (shop_id, item_id) = (sentence[0], sentence[1])\n",
    "    iid = item_dm[item_id]\n",
    "    sid = shop_dm[shop_id]\n",
    "    pr1 = 0\n",
    "    for k in range(6):\n",
    "        (shop_id, item_id) = (sentence[0], sentence[1])\n",
    "        iid = item_dm[item_id]\n",
    "        sid = shop_dm[shop_id]\n",
    "        pr1 = pr1 + table[iid][sid][28+k][1]\n",
    "        \n",
    "    pr2 = 0\n",
    "    (shop_id, item_id) = (sentence[0], sentence[1])\n",
    "    iid = item_dm[item_id]\n",
    "    sid = shop_dm[shop_id]\n",
    "    pr2 = pr2 + table[iid][sid][34-11][1]\n",
    "    pr2 = pr2 + table[iid][sid][34-12][1]\n",
    "    pr2 = pr2 + table[iid][sid][34-13][1]\n",
    "       \n",
    "    \n",
    "#     val = int(res[iid][sid]/120.0+pr1/35.0+pr2/25.0)\n",
    "    val = int(res[iid][sid]/40.0+pr1/18.0+pr2/6.0)\n",
    "    \n",
    "    \n",
    "#     test.loc[(shop_id, item_id)]['item_cnt_month'] = predict_test[item_dm[item_id]][shop_dm[shop_id]]\n",
    "    test.loc[(shop_id, item_id)]['item_cnt_month'] = val\n",
    "    summ=summ+val\n",
    "\n",
    "print(summ)\n",
    "    \n",
    "\n",
    "test = test.reset_index().drop(['shop_id', 'item_id'], axis=1)\n",
    "test.to_csv('submission2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = []\n",
    "for i in range(len(item_dm)):\n",
    "    res.append([])\n",
    "    for j in range(len(shop_dm)):\n",
    "        res[i].append([])\n",
    "        \n",
    "\n",
    "for index, sentence in enumerate(test2.index.values.tolist()):\n",
    "#     print(index, sentence)\n",
    "    (shop_id, item_id) = (sentence[0], sentence[1])\n",
    "    iid = item_dm[item_id]\n",
    "    sid = shop_dm[shop_id]\n",
    "    pr1 = 0\n",
    "    for k in range(6):\n",
    "        (shop_id, item_id) = (sentence[0], sentence[1])\n",
    "        iid = item_dm[item_id]\n",
    "        sid = shop_dm[shop_id]\n",
    "        pr1 = pr1 + table[iid][sid][28+k][1]\n",
    "        \n",
    "    pr2 = 0\n",
    "    (shop_id, item_id) = (sentence[0], sentence[1])\n",
    "    iid = item_dm[item_id]\n",
    "    sid = shop_dm[shop_id]\n",
    "    pr2 = pr2 + table[iid][sid][34-11][1]\n",
    "    pr2 = pr2 + table[iid][sid][34-12][1]\n",
    "    pr2 = pr2 + table[iid][sid][34-13][1]\n",
    "       \n",
    "    \n",
    "#     val = int(res[iid][sid]/120.0+pr1/35.0+pr2/25.0)\n",
    "    val = int(res[iid][sid]/40.0+pr1/18.0+pr2/6.0)\n",
    "    \n",
    "    \n",
    "#     test.loc[(shop_id, item_id)]['item_cnt_month'] = predict_test[item_dm[item_id]][shop_dm[shop_id]]\n",
    "    test.loc[(shop_id, item_id)]['item_cnt_month'] = val\n",
    "    summ=summ+val\n",
    "\n",
    "print(summ)\n",
    "    \n",
    "\n",
    "test = test.reset_index().drop(['shop_id', 'item_id'], axis=1)\n",
    "test.to_csv('submission2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 13894.0\n",
      "2 14562.0\n",
      "3 17846.0\n",
      "4 14988.0\n",
      "5 15285.0\n",
      "6 16531.0\n",
      "7 17669.0\n",
      "8 19671.0\n",
      "9 18520.0\n",
      "10 19843.0\n",
      "11 22259.0\n",
      "12 32155.0\n",
      "1 26523.0\n",
      "2 25855.0\n",
      "3 28559.0\n",
      "4 25255.0\n",
      "5 27037.0\n",
      "6 29634.0\n",
      "7 30912.0\n",
      "8 35568.0\n",
      "9 30658.0\n",
      "10 33945.0\n",
      "11 38947.0\n",
      "12 60033.0\n",
      "1 45672.0\n",
      "2 41246.0\n",
      "3 41986.0\n",
      "4 35651.0\n",
      "5 37283.0\n",
      "6 39126.0\n",
      "7 42008.0\n",
      "8 47794.0\n",
      "9 42015.0\n",
      "10 44724.0\n"
     ]
    }
   ],
   "source": [
    "summ = 0 \n",
    "\n",
    "# for i in range(len(item_dm)):\n",
    "# #     res.append([])\n",
    "#     for j in range(len(shop_dm)):\n",
    "# #         res[i].append([])\n",
    "# #         summ = 0\n",
    "# #         for k in range(34):\n",
    "# #             summ = summ+table[i][j][k][1]\n",
    "#         summ = table[i][j][33][1] + summ\n",
    "# #         if summ>maxx:\n",
    "# #             maxx=summ\n",
    "\n",
    "# print(summ)\n",
    "# summ = 0\n",
    "for k in range(34):\n",
    "    summ = 0\n",
    "    for sentence in test2.index.values.tolist():\n",
    "        (shop_id, item_id) = (sentence[0], sentence[1])\n",
    "        iid = item_dm[item_id]\n",
    "        sid = shop_dm[shop_id]\n",
    "        summ = summ + table[iid][sid][k][1]\n",
    "    print(((k)%12) + 1, summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('all/test.csv')\n",
    "test = test.set_index(['shop_id', 'item_id'])\n",
    "test['item_cnt_month'] = 0\n",
    "\n",
    "test2 = test\n",
    "test2\n",
    "for index, sentence in enumerate(test2.index.values.tolist()):\n",
    "#     print(index, sentence)\n",
    "    (shop_id, item_id) = (sentence[0], sentence[1])\n",
    "    val=0\n",
    "    p = 0\n",
    "    for j in range(5):\n",
    "        if predict_test[item_dm[item_id]][shop_dm[shop_id]*5+j] > p:\n",
    "            p = predict_test[item_dm[item_id]][shop_dm[shop_id]*5+j]\n",
    "            val = j\n",
    "#     test.loc[(shop_id, item_id)]['item_cnt_month'] = predict_test[item_dm[item_id]][shop_dm[shop_id]]\n",
    "    test.loc[(shop_id, item_id)]['item_cnt_month'] = val\n",
    "    \n",
    "    \n",
    "\n",
    "test = test.reset_index().drop(['shop_id', 'item_id'], axis=1)\n",
    "test.to_csv('submission2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 1.43 RMSE\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# make predictions\n",
    "# predict_train = model.predict(x_train)\n",
    "predict_val = model.predict(x_val)\n",
    "# invert predictions\n",
    "# predict_train = cnt_scaler.inverse_transform(predict_train)\n",
    "# yy_train = cnt_scaler.inverse_transform(y_train)\n",
    "predict_val = cnt_scaler.inverse_transform(predict_val)\n",
    "yy_val = cnt_scaler.inverse_transform(y_val)\n",
    "# calculate root mean squared error\n",
    "# trainScore = math.sqrt(mean_squared_error(predict_train, yy_train))\n",
    "# print('Train Score: %.2f RMSE' % (trainScore))\n",
    "valScore = math.sqrt(mean_squared_error(predict_val, yy_val))\n",
    "print('Test Score: %.2f RMSE' % (valScore))\n",
    "#For 1 epoch\n",
    "# Train Score: 2.31 RMSE\n",
    "# Test Score: 1.42 RMSE\n",
    "# 6 epoch\n",
    "# Train Score: 1.89 RMSE\n",
    "# Test Score: 1.98 RMSE\n",
    "# 10 epoch\n",
    "# Train Score: 1.53 RMSE\n",
    "# Test Score: 2.23 RMSE\n",
    "# 10 epoch\n",
    "# 16 LSTM\n",
    "# Train Score: 1.93 RMSE\n",
    "# Test Score: 1.90 RMSE\n",
    "# 10 epoch\n",
    "# 8 LSTM\n",
    "# Train Score: 2.31 RMSE\n",
    "# Test Score: 1.77 RMSE\n",
    "\n",
    "# 4 LSTM\n",
    "# Test Score: 1.52 RMSE\n",
    "\n",
    "# 1 LSTM\n",
    "# Test Score: 0.98 RMSE\n",
    "\n",
    "# 4 Dense, size 16, 10 epoch\n",
    "# 0.82\n",
    "\n",
    "\n",
    "# 5 Dense, size 16, 12 epoch\n",
    "# Test Score: 1.36 RMSE\n",
    "\n",
    "# Dense 16, 8, 8, 8, 8, \n",
    "# epoch 8\n",
    "# Test Score: 0.58 RMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134126\n",
      "134126\n"
     ]
    }
   ],
   "source": [
    "print(len(x_fin))\n",
    "print(len(y_fin))\n",
    "# print(len(y_train))\n",
    "# print(len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Epoch 1/5\n",
      "134126/134126 [==============================] - 5s 39us/step - loss: 0.2463\n",
      "Epoch 2/5\n",
      "134126/134126 [==============================] - 3s 25us/step - loss: 0.1808\n",
      "Epoch 3/5\n",
      "134126/134126 [==============================] - 3s 25us/step - loss: 0.1682\n",
      "Epoch 4/5\n",
      "134126/134126 [==============================] - 3s 25us/step - loss: 0.1671\n",
      "Epoch 5/5\n",
      "134126/134126 [==============================] - 3s 25us/step - loss: 0.1524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f897a26be80>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "# model.add(LSTM(1, input_shape=(maxlen, length)))\n",
    "# model.add(Dense(1, activation='relu'))\n",
    "\n",
    "\n",
    "# model.add(Dense(64, input_dim=length))\n",
    "model.add(Dense(16, input_dim=(length)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(8, input_dim=(length)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(8, input_dim=(length)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(8, input_dim=(length)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(8, input_dim=(length)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dropout(0.5))\n",
    "# model.add(Dense(16))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(LeakyReLU())\n",
    "model.add(Dense(1))\n",
    "# model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.005)\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "\n",
    "model.fit(x_fin, y_fin, batch_size=2048, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model.h5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_model.h5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "del predict_train\n",
    "del predict_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/13\n",
      "111404/111404 [==============================] - 19s 172us/step - loss: 9.2909\n",
      "Epoch 2/13\n",
      "111404/111404 [==============================] - 19s 172us/step - loss: 7.6454\n",
      "Epoch 3/13\n",
      "111404/111404 [==============================] - 19s 173us/step - loss: 6.8270\n",
      "Epoch 4/13\n",
      "111404/111404 [==============================] - 19s 173us/step - loss: 6.0881\n",
      "Epoch 5/13\n",
      "111404/111404 [==============================] - 19s 174us/step - loss: 5.6661\n",
      "Epoch 6/13\n",
      "111404/111404 [==============================] - 19s 173us/step - loss: 5.3044\n",
      "Epoch 7/13\n",
      "111404/111404 [==============================] - 19s 173us/step - loss: 5.0030\n",
      "Epoch 8/13\n",
      "111404/111404 [==============================] - 19s 172us/step - loss: 4.6944\n",
      "Epoch 9/13\n",
      "111404/111404 [==============================] - 19s 173us/step - loss: 4.3458\n",
      "Epoch 10/13\n",
      "111404/111404 [==============================] - 19s 171us/step - loss: 4.1903\n",
      "Epoch 11/13\n",
      "111404/111404 [==============================] - 19s 172us/step - loss: 3.9588\n",
      "Epoch 12/13\n",
      "111404/111404 [==============================] - 19s 171us/step - loss: 3.7914\n",
      "Epoch 13/13\n",
      "111404/111404 [==============================] - 19s 172us/step - loss: 3.4868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9d29e44f98>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_val, y_val, batch_size=2048, epochs=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test = model.predict(x_test)\n",
    "predict_test = cnt_scaler.inverse_transform(predict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test = pd.read_csv('all/test.csv')\n",
    "test = test.set_index(['shop_id', 'item_id'])\n",
    "test['item_cnt_month'] = 0\n",
    "\n",
    "for index, sentence in enumerate(x_test_o):\n",
    "    (shop_id, item_id) = (sentence[0]['shop_id'], sentence[0]['item_id'])\n",
    "    test.loc[(shop_id, item_id)]['item_cnt_month'] = predict_test[index]\n",
    "    \n",
    "    \n",
    "\n",
    "test = test.reset_index().drop(['shop_id', 'item_id'], axis=1)\n",
    "test.to_csv('submission2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
