{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import datetime, date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from math import ceil\n",
    "\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('all/sales_train.csv')\n",
    "test = pd.read_csv('all/test.csv')\n",
    "submission = pd.read_csv('all/sample_submission.csv')\n",
    "items = pd.read_csv('all/items.csv')\n",
    "item_cats = pd.read_csv('all/item_categories.csv')\n",
    "shops = pd.read_csv('all/shops.csv')\n",
    "print(\"Ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_shops = test.shop_id.unique()\n",
    "train = train[train.shop_id.isin(test_shops)]\n",
    "test_items = test.item_id.unique()\n",
    "train = train[train.item_id.isin(test_items)]\n",
    "\n",
    "MAX_BLOCK_NUM = train.date_block_num.max()\n",
    "MAX_ITEM = len(test_items)\n",
    "MAX_CAT = len(item_cats)\n",
    "MAX_YEAR = 3\n",
    "MAX_MONTH = 4 # 7 8 9 10\n",
    "MAX_SHOP = len(test_shops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.set_index('item_id').join(items.set_index('item_id')).drop('item_name', axis=1).reset_index()\n",
    "\n",
    "train['month'] = train.date.apply(lambda x: datetime.strptime(x, '%d.%m.%Y').strftime('%m'))\n",
    "train['year'] = train.date.apply(lambda x: datetime.strptime(x, '%d.%m.%Y').strftime('%Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('date', axis=1)\n",
    "train = train.drop('item_category_id', axis=1)\n",
    "train = train.groupby(['shop_id', 'item_id', 'date_block_num', 'month', 'year']).sum()\n",
    "train = train.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "cnt_scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(train.item_price.values.reshape(-1, 1))\n",
    "cnt_scaler.fit(train.item_cnt_day.values.reshape(-1, 1))\n",
    "\n",
    "train.item_price = scaler.transform(train.item_price.values.reshape(-1, 1))\n",
    "train.item_cnt_day = cnt_scaler.transform(train.item_cnt_day.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.reset_index().groupby(['item_id', 'date_block_num', 'shop_id']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = train.reset_index().set_index(['item_id', 'shop_id', 'date_block_num'])\n",
    "price = price.sort_index()\n",
    "# price"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(date_block):\n",
    "    date = datetime(2013, 1, 1)\n",
    "    date += relativedelta(months = date_block)\n",
    "    return (date.month, date.year)\n",
    "\n",
    "def closest_date_block(current_day, item_id, shop_id):\n",
    "    \"\"\"Find the block_date which is closest to the current_day, given item_id and shop_id. Returns index integer\"\"\"\n",
    "    if (item_id, shop_id) in price.index:\n",
    "        search_lst = np.array(price.loc[(item_id, shop_id)].index)        \n",
    "        return search_lst[np.abs(current_day - search_lst).argmin()]\n",
    "    return -1\n",
    "                \n",
    "def closest_price(current_day, item_id, shop_id):\n",
    "    closest_date = closest_date_block(current_day, item_id, shop_id)\n",
    "    if closest_date != -1:\n",
    "        return price.loc[( item_id, shop_id, closest_date )]['item_price']\n",
    "    return np.nan\n",
    "\n",
    "def closest_price_lambda(x):\n",
    "    return closest_price(34, x.item_id, x.shop_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert closest_date_block(18, 30, 5) == 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 2013)\n",
      "(7, 2014)\n",
      "(7, 2015)\n"
     ]
    }
   ],
   "source": [
    "# Some simple math to know what date_block_num to start learning\n",
    "print(convert(6))\n",
    "print(convert(18))\n",
    "print(convert(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "31189\n",
      "60878\n",
      "102423\n",
      "127852\n",
      "150809\n",
      "183234\n",
      "208675\n",
      "240080\n",
      "283521\n",
      "330586\n",
      "366323\n",
      "414480\n",
      "447733\n",
      "480890\n",
      "520263\n",
      "553024\n",
      "586421\n",
      "620730\n",
      "650695\n",
      "686696\n",
      "731145\n",
      "764554\n",
      "790151\n",
      "822264\n",
      "855469\n",
      "890066\n",
      "919431\n",
      "960448\n",
      "993629\n",
      "1023786\n",
      "1028575\n",
      "1066604\n",
      "1069629\n",
      "1100614\n",
      "1135979\n",
      "1167624\n",
      "1182757\n",
      "1218038\n",
      "1246227\n",
      "1279720\n",
      "1306757\n"
     ]
    }
   ],
   "source": [
    "maxlen = 4 # 4 months\n",
    "step = 1\n",
    "# 0: train, 1: val, 2:test\n",
    "sentences = [[],[],[]]\n",
    "next_chars = [[], []]\n",
    "BLOCKS = [6, 18, 30]\n",
    "\n",
    "count = 0\n",
    "\n",
    "for s in test_shops:\n",
    "    shop_items = list(train.loc[s].index.get_level_values(0).unique())\n",
    "#     print(len(shop_items))\n",
    "    print(count)\n",
    "    count = count + 1\n",
    "    for it in shop_items:     \n",
    "#         print(count)   \n",
    "        for i_index, i in enumerate(BLOCKS):\n",
    "            sentence = []\n",
    "#             start_time = time.time()  \n",
    "            closest_pc = closest_price(i, it, s) \n",
    "            for j in range(maxlen+1):\n",
    "                if j < maxlen:\n",
    "                    if (s, it, i+j) in train.index:\n",
    "                        r = train.loc[(s, it, i + j)].to_dict(orient='list')                    \n",
    "                        closest_pc = r['item_price'][0]\n",
    "                        item_cnt_day = r['item_cnt_day'][0]\n",
    "                        row = {'shop_id': s, 'date_block_num': i+j, 'item_cnt_day': item_cnt_day, \n",
    "                               'month': month, 'item_id': it, 'item_price': closest_pc, 'year': year}\n",
    "                    else:\n",
    "#                         closest_pc = closest_price(i, it, s)     \n",
    "                        month, year = convert(i+j)                    \n",
    "                        row = {'shop_id': s, 'date_block_num': i+j, 'item_cnt_day': 0, \n",
    "                               'month': month, 'item_id': it, 'item_price': closest_pc, 'year': year}\n",
    "                    sentence.append(row)\n",
    "                    count = count + 1\n",
    "                elif i_index < 2:   # not in test set\n",
    "                    next_chars[i_index].append(row)   \n",
    "            sentences[i_index].append(sentence)\n",
    "        \n",
    "#         print(\"--- %s seconds ---\" % (time.time() - start_time)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MAX_BLOCK_NUM = train.date_block_num.max()\n",
    "MAX_ITEM = len(test_items)\n",
    "MAX_CAT = len(item_cats)\n",
    "MAX_YEAR = 3\n",
    "MAX_MONTH = 4 # 7 8 9 10\n",
    "MAX_SHOP = len(test_shops)\n",
    "\n",
    "x_train_o = np.array(sentences[0])\n",
    "x_val_o = np.array(sentences[1])\n",
    "x_test_o = np.array(sentences[2])\n",
    "y_train = np.array([x['item_cnt_day'] for x in next_chars[0]])\n",
    "y_val = np.array([x['item_cnt_day'] for x in next_chars[1]])\n",
    "\n",
    "length = MAX_SHOP + MAX_ITEM + MAX_MONTH + 1 + 1 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'shop_id': 5,\n",
       "  'date_block_num': 6,\n",
       "  'item_cnt_day': 0,\n",
       "  'month': 7,\n",
       "  'item_id': 30,\n",
       "  'item_price': -0.2429610371380407,\n",
       "  'year': 2013},\n",
       " {'shop_id': 5,\n",
       "  'date_block_num': 7,\n",
       "  'item_cnt_day': 0,\n",
       "  'month': 8,\n",
       "  'item_id': 30,\n",
       "  'item_price': -0.2429610371380407,\n",
       "  'year': 2013},\n",
       " {'shop_id': 5,\n",
       "  'date_block_num': 8,\n",
       "  'item_cnt_day': 0,\n",
       "  'month': 9,\n",
       "  'item_id': 30,\n",
       "  'item_price': -0.2429610371380407,\n",
       "  'year': 2013},\n",
       " {'shop_id': 5,\n",
       "  'date_block_num': 9,\n",
       "  'item_cnt_day': -0.15018864969036175,\n",
       "  'month': 9,\n",
       "  'item_id': 30,\n",
       "  'item_price': -0.2757597800953987,\n",
       "  'year': 2013}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "shop_le = preprocessing.LabelEncoder()\n",
    "shop_le.fit(test_shops)\n",
    "shop_dm = dict(zip(test_shops, shop_le.transform(test_shops)))\n",
    "\n",
    "item_le = preprocessing.LabelEncoder()\n",
    "item_le.fit(test_items)\n",
    "item_dm = dict(zip(test_items, item_le.transform(test_items)))\n",
    "\n",
    "month_le = preprocessing.LabelEncoder()\n",
    "month_le.fit(range(7,11))\n",
    "month_dm = dict(zip(range(7,11), month_le.transform(range(7,11))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "Vectorization...\n",
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "def vectorize(inp):\n",
    "    print('Vectorization...')   \n",
    "    x = np.zeros((len(inp), maxlen, length), dtype=np.float32)\n",
    "    for i, sentence in enumerate(inp):\n",
    "        for t, char in enumerate(sentence):            \n",
    "            x[i][t][ shop_dm[char['shop_id']] ] = 1        \n",
    "            x[i][t][ MAX_SHOP + item_dm[char['item_id']] ] = 1\n",
    "            x[i][t][ MAX_SHOP + MAX_ITEM + month_dm[char['month']] ] = 1\n",
    "            x[i][t][ MAX_SHOP + MAX_ITEM + MAX_MONTH + 1 ] = char['item_price']\n",
    "            x[i][t][ MAX_SHOP + MAX_ITEM + MAX_MONTH + 1 + 1] = char['item_cnt_day']    \n",
    "    return x\n",
    "\n",
    "x_train = vectorize(x_train_o)\n",
    "x_val = vectorize(x_val_o)\n",
    "x_test = vectorize(x_test_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Epoch 1/6\n",
      "111404/111404 [==============================] - 10s 90us/step - loss: 0.1216\n",
      "Epoch 2/6\n",
      "111404/111404 [==============================] - 9s 82us/step - loss: 0.0809\n",
      "Epoch 3/6\n",
      "111404/111404 [==============================] - 9s 79us/step - loss: 0.0673\n",
      "Epoch 4/6\n",
      "111404/111404 [==============================] - 9s 82us/step - loss: 0.0606\n",
      "Epoch 5/6\n",
      "111404/111404 [==============================] - 9s 82us/step - loss: 0.0531\n",
      "Epoch 6/6\n",
      "111404/111404 [==============================] - 9s 79us/step - loss: 0.0490\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc6dfdd5ef0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(maxlen, length)))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.005)\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=2048, epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/13\n",
      "111404/111404 [==============================] - 10s 89us/step - loss: 0.0115\n",
      "Epoch 2/13\n",
      "111404/111404 [==============================] - 9s 81us/step - loss: 0.0090\n",
      "Epoch 3/13\n",
      "111404/111404 [==============================] - 9s 81us/step - loss: 0.0079\n",
      "Epoch 4/13\n",
      "111404/111404 [==============================] - 9s 81us/step - loss: 0.0074\n",
      "Epoch 5/13\n",
      "111404/111404 [==============================] - 9s 82us/step - loss: 0.0061\n",
      "Epoch 6/13\n",
      "111404/111404 [==============================] - 9s 79us/step - loss: 0.0055\n",
      "Epoch 7/13\n",
      "111404/111404 [==============================] - 9s 81us/step - loss: 0.0057\n",
      "Epoch 8/13\n",
      "111404/111404 [==============================] - 9s 81us/step - loss: 0.0045\n",
      "Epoch 9/13\n",
      "111404/111404 [==============================] - 9s 80us/step - loss: 0.0056\n",
      "Epoch 10/13\n",
      "111404/111404 [==============================] - 9s 80us/step - loss: 0.0048\n",
      "Epoch 11/13\n",
      "111404/111404 [==============================] - 9s 81us/step - loss: 0.0042\n",
      "Epoch 12/13\n",
      "111404/111404 [==============================] - 9s 82us/step - loss: 0.0054\n",
      "Epoch 13/13\n",
      "111404/111404 [==============================] - 9s 82us/step - loss: 0.0042\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcd793e60b8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_val, y_val, batch_size=2048, epochs=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test = model.predict(x_test)\n",
    "predict_test = cnt_scaler.inverse_transform(predict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test = pd.read_csv('all/test.csv')\n",
    "test = test.set_index(['shop_id', 'item_id'])\n",
    "test['item_cnt_month'] = 0\n",
    "\n",
    "for index, sentence in enumerate(x_test_o):\n",
    "    (shop_id, item_id) = (sentence[0]['shop_id'], sentence[0]['item_id'])\n",
    "    test.loc[(shop_id, item_id)]['item_cnt_month'] = predict_test[index]\n",
    "    \n",
    "    \n",
    "\n",
    "test = test.reset_index().drop(['shop_id', 'item_id'], axis=1)\n",
    "test.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
